{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "63183b46",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2, typing,numpy as np\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "42deefb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def __get_cv2_haarcascade_frontalface():\n",
    "    return cv2.CascadeClassifier(cv2.data.haarcascades + 'haarcascade_frontalface_default.xml')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1dc9b2ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "def __detect(classifier: cv2.CascadeClassifier, grayscale: np.ndarray, scale_factor: float, min_neighbors: int, min_size: typing.Tuple[int, int]) -> np.ndarray:\n",
    "    detections = classifier.detectMultiScale(\n",
    "        grayscale,\n",
    "        scaleFactor = scale_factor,\n",
    "        minNeighbors = min_neighbors,\n",
    "        minSize = min_size\n",
    "    )\n",
    "\n",
    "    return detections.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d1e9e8e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def __detect_face(classifier: cv2.CascadeClassifier, grayscale: np.ndarray) -> typing.Tuple[np.ndarray,np.ndarray]:\n",
    "    SCALE_FACTOR = 1.1\n",
    "    MIN_NEIGHBORS = 5\n",
    "    MIN_SIZE = (120, 120)\n",
    "    \n",
    "    face_range = __detect(classifier, grayscale, scale_factor = SCALE_FACTOR, min_neighbors = MIN_NEIGHBORS, min_size = MIN_SIZE)\n",
    "    \n",
    "    return grayscale, face_range"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec74671c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def __crop_face(face: np.ndarray, face_range: typing.List[int]) -> np.ndarray:\n",
    "    crops = []\n",
    "    for (x, y, w, h) in face_range:\n",
    "        crop = face[y:y+h, x:x+w]\n",
    "        crops.append(crop)\n",
    "\n",
    "    return crops[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aae28eb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get Classifier\n",
    "face_cascade = __get_cv2_haarcascade_frontalface()\n",
    "\n",
    "# Read Image\n",
    "image = cv2.imread('./dataset/face1.png')\n",
    "\n",
    "# To Grayscale\n",
    "grayscale = cv2.cvtColor(image, cv2.IMREAD_GRAYSCALE)\n",
    "\n",
    "# Detect Face (returns: face image, detected face range)\n",
    "face, face_range = __detect_face(face_cascade, grayscale)\n",
    "\n",
    "# Crop face from\n",
    "# (if the image contains a face, crop only the face from the image using the face image and face range.)\n",
    "cropped_face = __crop_face(face, face_range)\n",
    "\n",
    "# Show\n",
    "plt.imshow(cropped_face)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
